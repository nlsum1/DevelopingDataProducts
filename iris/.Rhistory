84-16
data(mtcars)
library(datasets)
head(mtcars)
t.test(mtcars$mpg)
library(datasets)
data(mtcars)
t.test(mtcars$mpg)
qt(.975,8)/3
?qt
qt(.975,8)
t.test(mtcars$mpg, var.equal=TRUE)
test4 <- mtcars$mpg[which(mtcars$cyl == 4)]
test6 <- mtcars$mpg[which(mtcars$cyl == 6)]
t.test(test4, test6, var.equal=TRUE)
?t.test
(1.5^2 + 1.8^2)/2
t.test(0.60, 0.68, var.equal=TRUE)
qt(.975,8)
1100 + c(-1,1)
qt(.975,8)*10
*1099
23*1099
1099*2.3
qt(.05,8)*10
qt(.975,8)*10
c(-1,1)*23
(3-5)+c(-1,1)*qt(0.975,8)*(sqrt(1.92)/(sqrt(1/10) + sqrt(1/10)))
qt(0.95,16)
c(-1,1)*0.4536
mt <- -3
mp <- 1
st <- 1.5
sp <- 1.8
nt <- 9
np <- 9
p <- 0.9
pooled_variance <- ((nt-1)*st^2 + (np-1)*sp^2)/(nt + np - 2)
ci <- mt - mp + c(-1,1) * qt(p + (1-p)/2, df=(nt+np-2)) * sqrt(pooled_variance) * sqrt(1/nt + 1/np)
p + (1-p)/2
sqrt(1/nt + 1/np)
library(swirl)
swirl()
6
(1:6)/6
(1+2+3+4+5+6)/6
expect_dice
dice_high
expect_dice(dice_high)
expect_dice(dice_low)
edh*edl
.5*(edh+edl)
integrate(0,2)
?integrate
?myfunc
myfunc(0)
integrate(myfunc,0.2)
integrate(myfunc,0,2)
spop
mean(spop)
allsam
apply(allsam, mean(allsam[0,3]))
apply(allsam, mean(allsam))
apply(allsam, FUN=mean(allsam))
apply(allsam, FUN=mean
)
apply(allsam, FUN=mean())
apply(allsam, FUN=mean(x))
apply(allsam, FUN=mean(allsam))
?apply
apply(allsam, (,3), mean)
apply(allsam, (1,3), mean)
apply(allsam, c(1,3), mean)
apply(allsam, 3, mean)
apply(allsam, 1, mean)
mean(smeans)
lambda <- 0.2
expo <- 40
n <- 1000
set.seed(123)
table <- data.frame(x =sapply(nsims, mean(rexp(n, lambda))));
?saaply
?sapply
means <- data.frame(x = sapply(nsims, function(x) {mean(rexp(n, lambda))}))
table <- data.frame(ncol=2,nrow=1000)
names(table) <- c("Index","Mean")
for (i in 1:n)
{
table[i,1] <- i
table[i,2] <- mean(rexp(n,lambda))
}
View(table)
sim <- data.frame(ncol=2,nrow=1000)
name(sim) <- c("no","mean")
for (i in 1:n)
{
sim[i,1] <- i
sim[i,2] <- mean(rexp(n,lambda))
}
mean(sim$Mean)
View(sim)
meanOfSim <- mean(sim$mean)
sim$mean
View(sim)
sim[,2]
meanOfSim <- mean(sim[,2])
meanOfExpo = 1 / lambda
varOfSim <- var(sim$mean)
varOfExpo <- ((1/lambda)^2)/40
varOfSim <- var(sim[,2])
varOfExpo <- ((1/lambda)^2)/40
var(sim[,2])
lambda <- 0.2
expo <- 40
n <- 1000
set.seed(123)
sim <- data.frame(ncol=2,nrow=1000)
for (i in 1:n)
{
sim[i,1] <- i
sim[i,2] <- mean(rexp(n,lambda))
}
meanOfSim <- mean(sim[,2])
meanOfExpo = 1 / lambda
varOfSim <- var(sim[,2])
varOfExpo <- ((1/lambda)^2)/40
names(sim) <- c("Index","Mean")
View(sim)
names(sim) <- c("no","mean")
varOfSim <- var(sim$mean)
sdOfExpo <- (1/lambda)/sqrt(n)
varOfExpo <- sdOfExpo^2
lambda <- 0.2
n <- 40
simno <- 1000
set.seed(123)
sim <- data.frame(ncol=2,nrow=1000)
for (i in 1:simno)
{
sim[i,1] <- i
sim[i,2] <- mean(rexp(n,lambda))
}
head(sim)
meanOfSim <- mean(sim[,2])
meanOfSim
meanOfExpo = 1 / lambda
meanofExpo
varOfSim <- var(sim[,2])
sdOfExpo <- (1/lambda)/sqrt(n)
varOfExpo <- sdOfExpo^2
ggplot(data = sim, aes(x = x)) +
geom_histogram(binwidth=0.1, aes(y=..density..)) +
labs(x="Means") +
labs(y="Density")
library(ggplot)
library(ggplot2)
ggplot(data = sim, aes(x = x)) +
geom_histogram(binwidth=0.1, aes(y=..density..)) +
labs(x="Means") +
labs(y="Density")
ggplot(data = sim, aes(x = mean)) +
geom_histogram(binwidth=0.1, aes(y=..density..)) +
labs(x="Means") +
labs(y="Density")
names(sim) <- c("no", "mean")
ggplot(data = sim, aes(x = mean)) +
geom_histogram(aes(y=..density..), fill = I('#00e6fa'),
binwidth = 0.20, color = I('black')) +
stat_function(fun = dnorm, arg = list(mean = 5, sd = sd(sim$mean)))
ggplot(data = sim, aes(x = mean)) +
geom_histogram(aes(y=..density..),
binwidth = 0.20, color = I('black')) +
stat_function(fun = dnorm, arg = list(mean = 5, sd = sd(sim$mean)))
ggplot(data = sim, aes(x = mean)) +
geom_histogram(aes(y=..density..),
binwidth = 0.20, color = "red" +
stat_function(fun = dnorm, arg = list(mean = 5, sd = sd(sim$mean)))
data(mtcars)
x<-mtcars$wt
y<-mtcars$mpg
lm(y~x)
coef<- lm(y~x)
fot<- lm(y~x)
fit<- lm(y~x)
summary(fit)$coefficients
sumco<- summary(fit)$coefficients
sumco[1,1]+c(-1,1)*qt(.975,dt=fit$df)*sumco[1,2]
sumco[1,1]+c(-1,1)*qt(.975,dt=fit$wt)*sumco[1,2]
sumco[1,1]+c(-1,1)*qt(.975,wt=fit$wt)*sumco[1,2]
predict(fit,data.frame(x=mean(x)), interval="confidence")
?mtcars
summart(fit)
summary(fit)
newdata<-data.frame(wt=3)
predict(fit,newdata, interval="confidence")
predict(fit, newdata, interval = ('prediction'))[3]
predict(fit,data.frame(x=3), interval="prediction")
predict(fit,data.frame(x=2), interval="prediction")
wtOvr2 <- mtcars$wt / 2
fit <- lm(mtcars$mpg ~ wtOvr2)
coef <- summary(fit)$coefficients
coef[2,1] - qt(.975, df = fit$df) * coef[2,2]
x<-mtcars$wt
y<-mtcars$mpg
coo <- lm(y~I(x/100))
summary(coo)$coeficient
summary(coo)$coeficients
coo
summary(coo)$coefficients
summary(lm(y~x))$coefficients
x <- c(0.61, 0.93, 0.83, 0.35, 0.54, 0.16, 0.91, 0.62, 0.62)
y <- c(0.67, 0.84, 0.6, 0.18, 0.85, 0.47, 1.1, 0.65, 0.36)
fit <- lm(y~x)
summary(fit)$coefficients
summary(fit)
x<-mtcars$wt
y<-mtcars$mpg
n <- length(y)
fit <- lm(y ~ x - 1)
beta1 <- summary(fit)$coefficients[1]
e <- y - beta1*x
sse1 <- sum(e^2)
?dfbeta
x <- c(0.586, 0.166, -0.042, -0.614, 11.72)
y <- c(0.549, -0.026, -0.127, -0.751, 1.344)
fit<-lm(x~y)
fit
summary(fit)
dfbeta(fit)
round(dfbetas(fit)[1 : 10, 2], 3)
1
round(dfbetas(fit))
dfbetas(fit)
round(hatvalues(fit))
hatvalues(fit)
influence.measures(fit)
fit<-lm(y~x)
influence.measures(fit)
x <- c(0.586, 0.166, -0.042, -0.614, 11.72)
y <- c(0.549, -0.026, -0.127, -0.751, 1.344)
fit<-lm(y~x)
influence.measures(fit)
dataset(mtcar)
datasets(mtcars)
dataset(mtcars)
library(dataset)
library(datasets)
datasets(mtcars)
dataset(mtcars)
data(mtcars)
heads(mtcars)
head(mtcars)
fit <- lm(mpg~cyl+wt, mtcars)
summary(fit)
fit <- lm(mpg~factor(cyl)+wt, mtcars)
summary(fit)
fit2 <- lm(mpg~factpr(cyl), mtcars)
fit2 <- lm(mpg~factor(cyl), mtcars)
summary(fit2)
fit1 <- lm(mpg~factor(cyl) + wt, data=mtcars)
fit2 <- update(fit1, mpg~factor(cyl) + wt + wt*factor(cyl))
summary(fit1)
summary(fit2)
anova(fit1,fit2)
lm(mpg ~ I(wt * 0.5) + factor(cyl), data = mtcars)
fitt<-lm(mpg ~ I(wt * 0.5) + factor(cyl), data = mtcars)
summary(fit)
x <- c(0.586, 0.166, -0.042, -0.614, 11.72)
y <- c(0.549, -0.026, -0.127, -0.751, 1.344)
fit <- lm(y ~ x)
influence.measures(fit)
influence.measures(fit)$infmat[5, 'dfb.x']
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
View(segmentationOriginal)
train<- segmentationOriginal[, which(segmentationOriginal$Case=="Train")]
train<- segmentationOriginal[which(segmentationOriginal$Case=="Train"),]
View(train)
test<- segmentationOriginal[which(segmentationOriginal$Case=="Test"),]
set.seed(125)
cart <- rpart(Case ~ *, train)
cart <- rpart(Case ~ ., train)
install.packeges(rpart)
install.packages(rpart)
install.packages("rpart")
install.packages("rpart")
library(rpart)
cart <- rpart(Case ~ ., train)
cart
?predict
dta <- data.frame(TotalIntench2 = 23,000; FiberWidthCh1 = 10; PerimStatusCh1=2 )
dta <- data.frame(TotalIntench2 = 23,000, FiberWidthCh1 = 10, PerimStatusCh1=2 )
View(dta)
pre <- predict(cart, newdata=dta)
fancyRpartPlot(cart)
install.packages("fancyRpartPlot")
library(fancyRpartPlot)
library("fancyRpartPlot")
install.packages("fancyRpartPlot")
library(rpart.plot)
install.packages("rpart.plot")
library(rpart.plot)
fancyRpartPlot(cart)
prp(cart)
prp(cart$finalModel)
cart <- rpart(Case ~ ., train, method="class")
prp(cart)
cart <- rpart(Case ~ ., data=train, method="class")
prp(cart)
cart <- rpart(Class ~ ., data=train, method="class")
prp(cart)
pre <- predict(cart, newdata=dta)
model<-train(Class ~ .,
data = train,
method = "rpart")
library(AppliedPredictiveModeling)
model<-train(Class ~ .,
data = train,
method = "rpart")
library(ElemStatLearn)
library(rattle)
install.packages("rattle")
library(rattle)
library(rattle)
model<-train(Class ~ .,
data = train,
method = "rpart")
library(train)
install.packages("train")
library(train)
prp(cart$finalModel)
cart$finalModel
cart
cart <- rpart(Class ~ ., data=train, method="class")
cart$finalModel
prp(cart)
install.packages("pgmm")
install.packages("ElemStatLearn")
install.packages("AppliedPredictiveModeling")
library(AppliedPredictiveModeling)
library(caret)
library(ElemStatLearn)
library(pgmm)
library(rpart)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
training<-segmentationOriginal[segmentationOriginal$Case=="Train",]
testing<-segmentationOriginal[segmentationOriginal$Case=="Test",]
set.seed(125)
model<-train(Class ~ .,
data = training,
method = "rpart")
prp(model)
library(rattle)
prp(model)
library(caTools)
prp(model)
library(rpart.plot)
prp(model)
model.fit = rpart(Class ~ ., data=train.q1, , method="class")
prp(model.fit)
model.fit = rpart(Class ~ ., data=training, , method="class")
prp(model.fit)
library(pgmm)
data(olive)
olive = olive[,-1]
View(olive)
newdata = as.data.frame(t(colMeans(olive)))
model <- train(Area~., data=olive, method="rpart")
predict(model, newdata)
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
set.seed(13234)
?lm
View(trainSA)
fit <- train(chd~age+alcohol+obesity+tobacco+typea+ldl, trainSA, method="glm",  family="binomial")
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
missClass(trainSA$chd, predict(model, trainSA))
missClass(trainSA$chd, predict(fit, trainSA))
missClass(testSA$chd, predict(fit, trainSA))
missClass(testSA$chd, predict(fit, testSA))
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
str(vowel.train)
vowel.train$y = as.factor(vowel.train$y)
vowel.test$y = as.factor(vowel.test$y)
set.seed(33833)
tree <- train(y~., data=vowel.train, method="rf", prox=TRUE)
?varImp
varImp(tree)
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
modelrf <- train(diagnosis~., data=training, method="rf")
modelgbm <- train(diagnosis~., data=training, method="gbm")
modellda <- train(diagnosis~., data=training, method="lda")
predrf <- predict(modelrf, testing)
predgbm <- predict(modelgbm, testing)
predlda <- predict(modellda, testing)
combined <- data.frame(predrf, predgbm, predlda, diagnosis=testing$diagnosis)
modelComb <- train(diagnosis~., data=combined, method="rf")
predComb <- predict(modelComb, testing)
rf<- confusionMatrix(testing$diagnosis, predrf)$overall['Accuracy']
gbm<- confusionMatrix(testing$diagnosis, predgbm)$overall['Accuracy']
lda<- confusionMatrix(testing$diagnosis, predlda)$overall['Accuracy']
comb<- confusionMatrix(testing$diagnosis, predComb)$overall['Accuracy']
rf
gbm
lda
comb
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(233)
View(testing)
lasso.model <- train(CompressiveStrength~., data=training, method="lasso")
plot.enet(lasso.model$finalModel, xvar="penalty", use.color=TRUE)
library(caret)
library(rpart)
library(rpart.plot)
library(randomForest)
install.packages("dev-tools")
library(rsconnect)
install.packages("devtools")
library(randomForest)
devtools::install_github('rstudio/rsconnect')
devtools::install_github('rstudio/shinyapps')
library(rsconnect)
devtools::install_github('rstudio/shinyapps')
shinyapps::setAccountInfo(name='nlsum', token='4A06A374DE6DCFD6235499A7CAE07098', secret='QYaGRv+uF3dvSkapC+QoAv9I9CV4aNVbj2BSkiFW')
devtools::install_github('rstudio/rsconnect')
install.packages("digest")
install.packages("digest")
devtools::install_github('rstudio/rsconnect')
devtools::install_github('rstudio/rsconnect')
devtools::install_github('rstudio/rsconnect')
devtools::install_github('rstudio/rsconnect')
shiny::runApp('G:/DataScience/Module 9 - Developing Data Products/assignment')
install.packages("digest")
install.packages("digest")
devtools::install_github('rstudio/rsconnect')
library(devtools)
devtools::install_github('rstudio/rsconnect')
devtools::install_github('rstudio/shinyapps')
install.packages('devtools')
install.packages("devtools")
devtools::install_github('rstudio/rsconnect')
devtools::install_github('rstudio/rsconnect')
library(rsconnect)
install.packages("rsconnect")
devtools::install_github('rstudio/rsconnect')
devtools::install_github('rstudio/rsconnect')
devtools::install_github('rstudio/rsconnect')
shinyapps::setAccountInfo(name='nlsum',
token='4A06A374DE6DCFD6235499A7CAE07098',
secret='QYaGRv+uF3dvSkapC+QoAv9I9CV4aNVbj2BSkiFW')
install.packages("shinyapps")
devtools::install_github('rstudio/rsconnect')
devtools::install_github('rstudio/shinyapps')
devtools::install_github('rstudio/test')
devtools::install_github('rstudio/rsconnect')
devtools::install_github('rstudio/shinyapps')
shiny::runApp('G:/DataScience/Module 9 - Developing Data Products/assignment')
shinyapps::setAccountInfo(name='nlsum', token='4A06A374DE6DCFD6235499A7CAE07098', secret='QYaGRv+uF3dvSkapC+QoAv9I9CV4aNVbj2BSkiFW')
devtools::install_github('rstudio/shinyapps')
shinyapps::setAccountInfo(name='nlsum',
token='4A06A374DE6DCFD6235499A7CAE07098',
secret='QYaGRv+uF3dvSkapC+QoAv9I9CV4aNVbj2BSkiFW')
shiny::runApp('G:/DataScience/Module 9 - Developing Data Products/assignment')
devtools::install_github('rstudio/rsconnect')
library(rsconnect)
getwd()
shiny::runApp('G:/DataScience/Module 9 - Developing Data Products/assignment')
shiny::runApp('G:/DataScience/Module 9 - Developing Data Products/assignment')
shiny::runApp('G:/DataScience/Module 9 - Developing Data Products/assignment')
shiny::runApp('G:/DataScience/Module 9 - Developing Data Products/assignment')
install_github('ramnathv/rCharts')
devtools::install_github('ramnathv/rCharts')
devtools::install_github('ramnathv/slidify')
devtools::install_github('ramnathv/slidify')
devtools::install_github('ramnathv/rCharts')
setwd("G:\\DataScience\\Module 9 - Developing Data Products\\assignment\\iris")
shiny::runApp()
View(iris)
?iris
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
